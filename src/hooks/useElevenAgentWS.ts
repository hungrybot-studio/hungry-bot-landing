"use client";

import { useCallback, useEffect, useRef, useState } from "react";

// ---- AUDIO OUT (AGENT ‚Üí PLAYER) ----
function b64ToBytes(b64: string): Uint8Array {
  const bin = atob(b64);
  const out = new Uint8Array(bin.length);
  for (let i = 0; i < bin.length; i++) out[i] = bin.charCodeAt(i);
  return out;
}

function bytesToB64(bytes: Uint8Array): string {
  let bin = "";
  for (let i = 0; i < bytes.length; i++) bin += String.fromCharCode(bytes[i]);
  return btoa(bin);
}

function writeString(view: DataView, offset: number, str: string) {
  for (let i = 0; i < str.length; i++) view.setUint8(offset + i, str.charCodeAt(i));
}

// PCM16 ‚Üí WAV (Base64)
function pcm16ToWavBase64(pcmB64: string, sampleRate = 16000, numChannels = 1) {
  const pcmBytes = b64ToBytes(pcmB64);
  const blockAlign = numChannels * 2;
  const byteRate = sampleRate * blockAlign;
  const dataSize = pcmBytes.length;
  const headerSize = 44;
  const totalSize = headerSize + dataSize;

  const buf = new ArrayBuffer(totalSize);
  const view = new DataView(buf);

  writeString(view, 0, "RIFF");
  view.setUint32(4, 36 + dataSize, true);
  writeString(view, 8, "WAVE");
  writeString(view, 12, "fmt ");
  view.setUint32(16, 16, true);
  view.setUint16(20, 1, true); // PCM
  view.setUint16(22, numChannels, true);
  view.setUint32(24, sampleRate, true);
  view.setUint32(28, byteRate, true);
  view.setUint16(32, blockAlign, true);
  view.setUint16(34, 16, true);
  writeString(view, 36, "data");
  view.setUint32(40, dataSize, true);

  new Uint8Array(buf, headerSize).set(pcmBytes);
  return bytesToB64(new Uint8Array(buf));
}

function detectFormat(b64: string): "mp3" | "wav" | "pcm16" {
  const h = b64.slice(0, 16);
  if (h.startsWith("SUQz") || h.startsWith("/+")) return "mp3"; // ID3 / MP3 frame
  if (h.startsWith("UklG")) return "wav"; // RIFF
  return "pcm16"; // Eleven —á–∞—Å—Ç–æ —à–ª–µ —Å–∏—Ä–∏–π PCM16
}

function blobUrlFromBase64(b64: string, mime: string) {
  const bin = b64ToBytes(b64);
  return URL.createObjectURL(new Blob([bin], { type: mime }));
}

function createAudioQueue() {
  const q: string[] = [];
  let playing = false;
  const playNext = () => {
    const url = q.shift();
    if (!url) { playing = false; return; }
    playing = true;
    const a = new Audio(url);
    a.onended = a.onerror = () => { URL.revokeObjectURL(url); playNext(); };
    a.play().catch(() => playNext());
  };
  return { enqueue(url: string) { q.push(url); if (!playing) playNext(); } };
}

// ---- AUDIO IN (MIC ‚Üí WS; PCM16 16k) ----
function floatTo16BitPCM(f32: Float32Array): Int16Array {
  const out = new Int16Array(f32.length);
  for (let i = 0; i < f32.length; i++) {
    let s = Math.max(-1, Math.min(1, f32[i]));
    out[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
  }
  return out;
}

function resampleTo16k(input: Float32Array, fromRate: number): Float32Array {
  if (fromRate === 16000) return input;
  const ratio = fromRate / 16000;
  const newLen = Math.round(input.length / ratio);
  const out = new Float32Array(newLen);
  let pos = 0;
  for (let i = 0; i < newLen; i++) {
    const idx = i * ratio;
    const i0 = Math.floor(idx);
    const i1 = Math.min(i0 + 1, input.length - 1);
    const frac = idx - i0;
    out[i] = input[i0] * (1 - frac) + input[i1] * frac;
  }
  return out;
}

// ---- —É—Ç–∏–ª—ñ—Ç–∏ –∞—É–¥—ñ–æ ----
function unlockAudioContextOnce() {
  // –†–æ–∑–±–ª–æ–∫—É–≤–∞—Ç–∏ –∞–≤—Ç–æ–ø–ª–µ–π —É iOS/Safari/Chrome: —Ç–∏—Ö–∏–π ¬´–±—ñ–ø¬ª 50 –º—Å
  try {
    const Ctx = window.AudioContext || (window as any).webkitAudioContext;
    if (!Ctx) return Promise.resolve();
    const ctx = new Ctx();
    if (ctx.state === "suspended") return ctx.resume();
    const o = ctx.createOscillator();
    const g = ctx.createGain();
    g.gain.value = 0.0001;
    o.connect(g).connect(ctx.destination);
    o.start();
    o.stop(ctx.currentTime + 0.05);
    return Promise.resolve();
  } catch { return Promise.resolve(); }
}







// ---- –æ—Å–Ω–æ–≤–Ω–∏–π —Ö—É–∫ ----
export function useElevenAgentWS(agentId: string) {
  const wsRef = useRef<WebSocket | null>(null);
  const workRef = useRef<{ ctx?: AudioContext; node?: ScriptProcessorNode } | null>(null);
  const metaRef = useRef<{ sampleRate: number; channels: number }>({ sampleRate: 16000, channels: 1 });
  const [connected, setConnected] = useState(false);
  const [status, setStatus] = useState<"idle"|"connecting"|"talking">("idle");
  const q = useRef(createAudioQueue());

  // WebAudio —Ñ—É–Ω–∫—Ü—ñ—ó
  async function startPcmStream(ws: WebSocket, stream: MediaStream) {
    // 1) AudioContext (—è–∫—â–æ –≤ Safari —ñ–≥–Ω–æ—Ä—É—î sampleRate ‚Äî –º–∏ –≤—Å–µ –æ–¥–Ω–æ —Ä–µ—Å–µ–º–ø–ª–∏–º–æ)
    const ACtx = (window.AudioContext || (window as any).webkitAudioContext);
    const ctx = new ACtx({ sampleRate: 16000 });

    const source = ctx.createMediaStreamSource(stream);
    // bufferSize 2048/4096 ‚Äî –Ω–æ—Ä–º; 1 –∫–∞–Ω–∞–ª –º–æ–Ω–æ
    const node = ctx.createScriptProcessor(2048, 1, 1);

    node.onaudioprocess = (e) => {
      const input = e.inputBuffer.getChannelData(0); // Float32 [-1..1] @ ctx.sampleRate (—á–∞—Å—Ç–æ 48k)
      const f32_16k = resampleTo16k(input, ctx.sampleRate);
      const pcm16 = floatTo16BitPCM(f32_16k);
      const b64 = bytesToB64(new Uint8Array(pcm16.buffer));
      if (ws.readyState === WebSocket.OPEN) {
        ws.send(JSON.stringify({ user_audio_chunk: b64 }));
      }
    };

    source.connect(node);
    // —â–æ–± node –ø—Ä–∞—Ü—é–≤–∞–≤ —Å—Ç–∞–±—ñ–ª—å–Ω–æ ‚Äî –ø—ñ–¥ º—î–¥–Ω—É—î–º–æ –π–æ–≥–æ –¥–æ destination —Ç–∏—Ö–æ
    const gain = ctx.createGain();
    gain.gain.value = 0.0; // –±–µ–∑ –∑–≤—É–∫—É
    node.connect(gain).connect(ctx.destination);

    workRef.current = { ctx, node };
  }

  function stopPcmStream() {
    try {
      workRef.current?.node?.disconnect();
      workRef.current?.ctx?.close();
    } catch {}
    workRef.current = null;
  }

     const start = useCallback(async () => {
     if (connected || status === "connecting") return;
     console.log('üöÄ Starting ElevenLabs agent connection...');
     setStatus("connecting");

     await unlockAudioContextOnce();

     // 1) –î–æ—Å—Ç—É–ø –¥–æ –º—ñ–∫—Ä–æ—Ñ–æ–Ω–∞
     console.log('üé§ Requesting microphone access...');
     const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
     console.log('‚úÖ Microphone access granted');

     // 2) –í—ñ–¥–∫—Ä–∏—Ç–∏ WebSocket –Ω–∞–ø—Ä—è–º—É –¥–æ –ø—É–±–ª—ñ—á–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
     const url = `wss://api.elevenlabs.io/v1/convai/conversation?agent_id=${agentId}`;
     console.log('üîó Connecting to:', url);
     const ws = new WebSocket(url);

         ws.onopen = async () => {
       console.log('üîó WebSocket connected to ElevenLabs');
       setConnected(true);
       setStatus("talking");

       // (–∞) –ø—Ä–æ—Å–∏–º–æ MP3 44.1k/128–∫–±—ñ—Ç —è–∫ —É —ó—Ö REST-–ø—Ä–∏–∫–ª–∞–¥–∞—Ö
       console.log('üéØ Requesting MP3 format from agent...');
       ws.send(JSON.stringify({
         type: "set_response_audio_format",
         response_audio_format: { type: "mp3", sample_rate: 44100, bitrate_bps: 128000 }
       }));

       // (–±) —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –¥—ñ–∞–ª–æ–≥—É (—è–∫ —ñ –±—É–ª–æ)
       ws.send(JSON.stringify({ type: "conversation_initiation_client_data" }));

       // (–≤) —Å—Ç–∞—Ä—Ç—É—î–º–æ –∑–∞—Ö–æ–ø–ª–µ–Ω–Ω—è –º—ñ–∫—Ä–æ—Ñ–æ–Ω–∞ —á–µ—Ä–µ–∑ WebAudio
       await startPcmStream(ws, stream);
     };

         ws.onmessage = (e) => {
       const msg = JSON.parse(e.data);
       console.log('üîç WebSocket message received:', msg);

       // –ó–±–∏—Ä–∞—î–º–æ –º–µ—Ç–∞–¥–∞–Ω—ñ —Å–µ—Å—ñ—ó
       if (msg.type === "conversation_initiation_metadata" && msg.conversation_initiation_metadata_event) {
         const ev = msg.conversation_initiation_metadata_event;
         console.log("üß© init metadata:", ev);

         // –ü—Ä–∏–∫–ª–∞–¥–∏ –∑ –ª–æ–≥—ñ–≤:
         // agent_output_audio_format: 'pcm_16000'
         // user_input_audio_format:  'pcm_16000'
         const parseHz = (v?: string) => {
           if (typeof v !== "string") return undefined;
           const m = v.match(/(\d{4,6})$/); // –≤–∏—Ç—è–≥–Ω—É—Ç–∏ 16000/22050/44100 –∑ –∫—ñ–Ω—Ü—è
           return m ? parseInt(m[1], 10) : undefined;
         };

         const sr =
           parseHz(ev.agent_output_audio_format) ||
           parseHz(ev.output_audio_format) ||
           Number(ev.sample_rate) ||
           16000;

         const ch =
           Number(ev.channels) ||
           Number(ev.num_channels) ||
           1;

         metaRef.current = { sampleRate: sr, channels: ch };
         console.log("üéõÔ∏è Audio config:", metaRef.current);
         return;
       }

       // ping/pong –¥–ª—è –ø—ñ–¥—Ç—Ä–∏–º–∫–∏ –∑ º—î–¥–Ω–∞–Ω–Ω—è
       if (msg.type === "ping" && msg.ping_event?.event_id != null) {
         console.log('üèì Ping received, sending pong');
         ws.send(JSON.stringify({ type: "pong", event_id: msg.ping_event.event_id }));
         return;
       }

       // –æ—Å–Ω–æ–≤–Ω–µ ‚Äî –∞—É–¥—ñ–æ –≤—ñ–¥ –∞–≥–µ–Ω—Ç–∞ —É base64
       if (msg.type === "audio" && msg.audio_event?.audio_base_64) {
         const b64 = msg.audio_event.audio_base_64;

         // –¥–µ—Ç–µ–∫—Ç —Ñ–æ—Ä–º–∞—Ç—É (—è–∫ —É —Ç–µ–±–µ –±—É–ª–æ)
         const fmt = detectFormat(b64);

         if (fmt === "mp3") {
           const url = blobUrlFromBase64(b64, "audio/mpeg");
           console.log('üéµ Playing MP3 audio');
           q.current.enqueue(url);
           return;
         }
         if (fmt === "wav") {
           const url = blobUrlFromBase64(b64, "audio/wav");
           console.log('üéµ Playing WAV audio');
           q.current.enqueue(url);
           return;
         }

         // —Å–∏—Ä–∏–π PCM16 ‚Üí –∑–∞–≥–æ—Ä—Ç–∞—î–º–æ —É WAV –∑ –ü–†–ê–í–ò–õ–¨–ù–ò–ú Hz
         const sr = metaRef.current?.sampleRate || 16000;
         const ch = metaRef.current?.channels || 1;

         const wavB64 = pcm16ToWavBase64(b64, sr, ch);
         const url = blobUrlFromBase64(wavB64, "audio/wav");
         console.log(`üéµ Playing PCM16 as WAV @ ${sr}Hz`);
         q.current.enqueue(url);
         return;
       }

       // —Ç–µ–∫—Å—Ç, —è–∫–∏–π –≥–æ–≤–æ—Ä–∏—Ç—å –∞–≥–µ–Ω—Ç
       if (msg.type === "agent_response") {
         console.log('ü§ñ Agent response:', msg.agent_response_event?.agent_response);
       }

       // —â–æ –ø–æ—á—É–≤ –≤—ñ–¥ –Ω–∞—Å
       if (msg.type === "user_transcript") {
         console.log('üë§ User transcript:', msg.user_transcription_event?.user_transcript);
       }

       // –ø–µ—Ä–µ–≤—ñ—Ä–∏–º–æ —ñ–Ω—à—ñ —Ç–∏–ø–∏ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å
       if (msg.type === "conversation_initiation_server_data") {
         console.log('‚úÖ Conversation initiated by server');
       }

       if (msg.type === "interruption") {
         console.log('‚ö†Ô∏è Interruption:', msg.interruption_event?.reason);
       }
     };

         ws.onerror = (error) => { 
       console.error('‚ùå WebSocket error:', error);
     };

     ws.onclose = (event) => {
       console.log('üîå WebSocket closed:', event.code, event.reason);
       stopPcmStream();
       try { stream.getTracks().forEach(t => t.stop()); } catch {}
       wsRef.current = null;
       setConnected(false);
       setStatus("idle");
     };

    wsRef.current = ws;
  }, [agentId, connected, status]);

  const stop = useCallback(() => {
    stopPcmStream();
    try { wsRef.current?.close(); } catch {}
  }, []);

  useEffect(() => () => {
    stopPcmStream();
    try { wsRef.current?.close(); } catch {}
  }, []);

  return { start, stop, connected, status };
}
